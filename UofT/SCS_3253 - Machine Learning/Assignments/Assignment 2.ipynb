{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your name:\n",
    "\n",
    "<pre> SV</pre>\n",
    "\n",
    "### Collaborators:\n",
    "\n",
    "<pre> Enter the name of the people you worked with if any</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the housing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()\n",
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build full pipeline for the data analysis following the example of the notebook.\n",
    " Hint: the main part requested to change is the algorithm used (Lasso regression)\n",
    "\n",
    "If you want to learn more about the Lasso regression, see resources below:\n",
    "- http://scikit-learn.org/stable/modules/linear_model.html#lasso\n",
    "- https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations for building pipeline:\n",
    "\n",
    "- Split data into training and testing sets below.\n",
    "- Convert all categorical data to one-hot vectors below\n",
    "- Normalize all non-categorical data \n",
    "-  Perform Lasso-based regression using a variety of values for $\\alpha$ between 0 and 1 via a grid search where  *housing_labels* is the output and all other features are the input (similar to as seen in lecture two.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clockwork\\Anaconda2\\envs\\python35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\clockwork\\Anaconda2\\envs\\python35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Write your code here:\n",
    "\n",
    "# STEP 1: split the data into training (80%) and test (20%) sets - create a stratified sample based on income \n",
    "# category\n",
    "# Divide by 1.5 to limit the number of income categories\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "# Label those above 5 as 5\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "# Do the split\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "# Drop the income category column as we don't need it any more.    \n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "# STEP 2: prepare the data for machine learning algorithms\n",
    "# STEP 2A: drop target values from training set and copy to a new list\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) \n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "\n",
    "# STEP 3: Add new calculated fields: \n",
    "# create a custom transformer to add extra attributes:\n",
    "# column index\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "\n",
    "housing_extra_attribs = pd.DataFrame(\n",
    "    housing_extra_attribs,\n",
    "    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"])\n",
    "\n",
    "\n",
    "# STEP 4: build a pipeline for preprocessing the numerical attributes\n",
    "housing_num = housing.drop('ocean_proximity', axis=1)\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', Imputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "# STEP 5: create a mechanism to separate numerical and categorical features\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "\n",
    "# STEP 6: view housing_prepared dataset\n",
    "housing_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 2.6}\n",
      "Lasso(alpha=2.6, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=999,\n",
      "   selection='cyclic', tol=0.1, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# STEP 7: fit a lasso regression model\n",
    "# Perform hyper-parameter tuning by doing a grid search with varying values of alpha\n",
    "lassoRegressionModel = Lasso(random_state=999, tol=0.1)\n",
    "param_grid = [\n",
    "    # try \n",
    "    {'alpha': np.arange(0.1, 10, 0.1) }\n",
    "  ]\n",
    "\n",
    "# Fit our training set to this model\n",
    "lasso_grid_search = GridSearchCV(lassoRegressionModel, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "lasso_grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# Print details of the hyper parameters that worked best\n",
    "print(lasso_grid_search.best_params_)\n",
    "print(lasso_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.6</td>\n",
       "      <td>-4.781230e+09</td>\n",
       "      <td>69146.436445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.9</td>\n",
       "      <td>-4.781230e+09</td>\n",
       "      <td>69146.441790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.5</td>\n",
       "      <td>-4.781231e+09</td>\n",
       "      <td>69146.446315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.781232e+09</td>\n",
       "      <td>69146.453846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.2</td>\n",
       "      <td>-4.781234e+09</td>\n",
       "      <td>69146.468209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.2</td>\n",
       "      <td>-4.781234e+09</td>\n",
       "      <td>69146.469634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.4</td>\n",
       "      <td>-4.781235e+09</td>\n",
       "      <td>69146.471407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.1</td>\n",
       "      <td>-4.781235e+09</td>\n",
       "      <td>69146.476498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.3</td>\n",
       "      <td>-4.781235e+09</td>\n",
       "      <td>69146.478130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.1</td>\n",
       "      <td>-4.781237e+09</td>\n",
       "      <td>69146.490576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.7</td>\n",
       "      <td>-4.781238e+09</td>\n",
       "      <td>69146.493068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>-4.781240e+09</td>\n",
       "      <td>69146.509689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.4</td>\n",
       "      <td>-4.781240e+09</td>\n",
       "      <td>69146.510731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>-4.781240e+09</td>\n",
       "      <td>69146.511562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.3</td>\n",
       "      <td>-4.781240e+09</td>\n",
       "      <td>69146.513422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.5</td>\n",
       "      <td>-4.781241e+09</td>\n",
       "      <td>69146.519299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.9</td>\n",
       "      <td>-4.781243e+09</td>\n",
       "      <td>69146.530852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.8</td>\n",
       "      <td>-4.781243e+09</td>\n",
       "      <td>69146.533016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.7</td>\n",
       "      <td>-4.781246e+09</td>\n",
       "      <td>69146.554992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.6</td>\n",
       "      <td>-4.781247e+09</td>\n",
       "      <td>69146.563020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.6</td>\n",
       "      <td>-4.781248e+09</td>\n",
       "      <td>69146.568337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.7</td>\n",
       "      <td>-4.781249e+09</td>\n",
       "      <td>69146.576096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.5</td>\n",
       "      <td>-4.781254e+09</td>\n",
       "      <td>69146.614434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-4.781255e+09</td>\n",
       "      <td>69146.621757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.9</td>\n",
       "      <td>-4.781258e+09</td>\n",
       "      <td>69146.643919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.8</td>\n",
       "      <td>-4.781259e+09</td>\n",
       "      <td>69146.648057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-4.781262e+09</td>\n",
       "      <td>69146.668641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.2</td>\n",
       "      <td>-4.781264e+09</td>\n",
       "      <td>69146.681068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.1</td>\n",
       "      <td>-4.781269e+09</td>\n",
       "      <td>69146.722685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>-4.781269e+09</td>\n",
       "      <td>69146.723641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9.9</td>\n",
       "      <td>-4.781572e+09</td>\n",
       "      <td>69148.908193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9.8</td>\n",
       "      <td>-4.781572e+09</td>\n",
       "      <td>69148.911260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9.1</td>\n",
       "      <td>-4.781582e+09</td>\n",
       "      <td>69148.986186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>9.5</td>\n",
       "      <td>-4.781584e+09</td>\n",
       "      <td>69148.996716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9.4</td>\n",
       "      <td>-4.781585e+09</td>\n",
       "      <td>69149.006843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9.2</td>\n",
       "      <td>-4.781586e+09</td>\n",
       "      <td>69149.016412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9.3</td>\n",
       "      <td>-4.781587e+09</td>\n",
       "      <td>69149.018517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6.8</td>\n",
       "      <td>-4.781594e+09</td>\n",
       "      <td>69149.073030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8.7</td>\n",
       "      <td>-4.781599e+09</td>\n",
       "      <td>69149.109028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>9</td>\n",
       "      <td>-4.781602e+09</td>\n",
       "      <td>69149.128018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8.9</td>\n",
       "      <td>-4.781604e+09</td>\n",
       "      <td>69149.146740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8.8</td>\n",
       "      <td>-4.781607e+09</td>\n",
       "      <td>69149.167009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.9</td>\n",
       "      <td>-4.781616e+09</td>\n",
       "      <td>69149.227817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8.5</td>\n",
       "      <td>-4.781624e+09</td>\n",
       "      <td>69149.286922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8.2</td>\n",
       "      <td>-4.781626e+09</td>\n",
       "      <td>69149.301881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8.4</td>\n",
       "      <td>-4.781627e+09</td>\n",
       "      <td>69149.308547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>8.6</td>\n",
       "      <td>-4.781628e+09</td>\n",
       "      <td>69149.316005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8.3</td>\n",
       "      <td>-4.781628e+09</td>\n",
       "      <td>69149.317462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>7</td>\n",
       "      <td>-4.781644e+09</td>\n",
       "      <td>69149.430895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8.1</td>\n",
       "      <td>-4.781646e+09</td>\n",
       "      <td>69149.445308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>7.1</td>\n",
       "      <td>-4.781649e+09</td>\n",
       "      <td>69149.467017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>8</td>\n",
       "      <td>-4.781650e+09</td>\n",
       "      <td>69149.474578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>7.8</td>\n",
       "      <td>-4.781651e+09</td>\n",
       "      <td>69149.485955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>7.9</td>\n",
       "      <td>-4.781652e+09</td>\n",
       "      <td>69149.491686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-4.781672e+09</td>\n",
       "      <td>69149.638103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7.2</td>\n",
       "      <td>-4.781673e+09</td>\n",
       "      <td>69149.644759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7.6</td>\n",
       "      <td>-4.781679e+09</td>\n",
       "      <td>69149.682073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7.5</td>\n",
       "      <td>-4.781683e+09</td>\n",
       "      <td>69149.714660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7.4</td>\n",
       "      <td>-4.781684e+09</td>\n",
       "      <td>69149.724917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7.3</td>\n",
       "      <td>-4.781697e+09</td>\n",
       "      <td>69149.812580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_alpha  mean_test_score          rmse\n",
       "25         2.6    -4.781230e+09  69146.436445\n",
       "28         2.9    -4.781230e+09  69146.441790\n",
       "24         2.5    -4.781231e+09  69146.446315\n",
       "27         2.8    -4.781232e+09  69146.453846\n",
       "21         2.2    -4.781234e+09  69146.468209\n",
       "31         3.2    -4.781234e+09  69146.469634\n",
       "23         2.4    -4.781235e+09  69146.471407\n",
       "30         3.1    -4.781235e+09  69146.476498\n",
       "22         2.3    -4.781235e+09  69146.478130\n",
       "20         2.1    -4.781237e+09  69146.490576\n",
       "26         2.7    -4.781238e+09  69146.493068\n",
       "19           2    -4.781240e+09  69146.509689\n",
       "33         3.4    -4.781240e+09  69146.510731\n",
       "29           3    -4.781240e+09  69146.511562\n",
       "32         3.3    -4.781240e+09  69146.513422\n",
       "34         3.5    -4.781241e+09  69146.519299\n",
       "18         1.9    -4.781243e+09  69146.530852\n",
       "17         1.8    -4.781243e+09  69146.533016\n",
       "16         1.7    -4.781246e+09  69146.554992\n",
       "35         3.6    -4.781247e+09  69146.563020\n",
       "15         1.6    -4.781248e+09  69146.568337\n",
       "36         3.7    -4.781249e+09  69146.576096\n",
       "14         1.5    -4.781254e+09  69146.614434\n",
       "13         1.4    -4.781255e+09  69146.621757\n",
       "38         3.9    -4.781258e+09  69146.643919\n",
       "37         3.8    -4.781259e+09  69146.648057\n",
       "12         1.3    -4.781262e+09  69146.668641\n",
       "11         1.2    -4.781264e+09  69146.681068\n",
       "40         4.1    -4.781269e+09  69146.722685\n",
       "39           4    -4.781269e+09  69146.723641\n",
       "..         ...              ...           ...\n",
       "98         9.9    -4.781572e+09  69148.908193\n",
       "97         9.8    -4.781572e+09  69148.911260\n",
       "90         9.1    -4.781582e+09  69148.986186\n",
       "94         9.5    -4.781584e+09  69148.996716\n",
       "93         9.4    -4.781585e+09  69149.006843\n",
       "91         9.2    -4.781586e+09  69149.016412\n",
       "92         9.3    -4.781587e+09  69149.018517\n",
       "67         6.8    -4.781594e+09  69149.073030\n",
       "86         8.7    -4.781599e+09  69149.109028\n",
       "89           9    -4.781602e+09  69149.128018\n",
       "88         8.9    -4.781604e+09  69149.146740\n",
       "87         8.8    -4.781607e+09  69149.167009\n",
       "68         6.9    -4.781616e+09  69149.227817\n",
       "84         8.5    -4.781624e+09  69149.286922\n",
       "81         8.2    -4.781626e+09  69149.301881\n",
       "83         8.4    -4.781627e+09  69149.308547\n",
       "85         8.6    -4.781628e+09  69149.316005\n",
       "82         8.3    -4.781628e+09  69149.317462\n",
       "69           7    -4.781644e+09  69149.430895\n",
       "80         8.1    -4.781646e+09  69149.445308\n",
       "70         7.1    -4.781649e+09  69149.467017\n",
       "79           8    -4.781650e+09  69149.474578\n",
       "77         7.8    -4.781651e+09  69149.485955\n",
       "78         7.9    -4.781652e+09  69149.491686\n",
       "76         7.7    -4.781672e+09  69149.638103\n",
       "71         7.2    -4.781673e+09  69149.644759\n",
       "75         7.6    -4.781679e+09  69149.682073\n",
       "74         7.5    -4.781683e+09  69149.714660\n",
       "73         7.4    -4.781684e+09  69149.724917\n",
       "72         7.3    -4.781697e+09  69149.812580\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres = pd.DataFrame(lasso_grid_search.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "cvres['rmse'] = cvres['mean_test_score'].apply(lambda x: np.sqrt(-x))\n",
    "# Display grid search results ordered by mean_test_score\n",
    "cvres.sort_values('mean_test_score', ascending=False)[['param_alpha', 'mean_test_score', 'rmse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68628.6226919338"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "best_model = lasso_grid_search.best_estimator_\n",
    "housing_predictions = best_model.predict(housing_prepared)\n",
    "lasso_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lasso_rmse = np.sqrt(lasso_mse)\n",
    "lasso_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Why is it necessary to normalize all continuous variables before performing Lasso? (OPTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Lasso regression works by minimizing the error in predicted values along with the absolute values of the coefficients of each of the predictors. For this reason, it is important to have all features/predictors on similar scales as features that have larger magnitudes will be penalized heavier than features that have smallar magnitudes. If all features are normalized, they are on comparable scales and their coefficients will have comparable magnitudes and will be penalized more equitably. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "For what values of $\\alpha$ does Lasso perform best? Does it perform as well on the housing data as the linear regressor from the lectures? Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Lasso seemed to perform best for an Alpha value of 2.6. \n",
    "The linear regressor seems to perform slightly better than the Lasso regressor based on root mean error values.  \n",
    "Lasso regression forces coefficients of certain features to zero and/or selects randomly between co-related/colinear variables, keeping one and losing the other in order to minimize the objective function. This can result in underfitting, especially for larger values of alpha. This might explain the difference in performance compared to Linear Regression. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read appending B\n",
    "\n",
    "- Reflect on your last data project, read appendix B. Then, write down a few of the checklist items that your last data project could have used. If you have not yet done a data project, then write down a few of the items that you found most interesting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>My last data project (as part of this course) involved the analysis of BikeShare ridership data for the City of Toronto.\n",
    "It involved most of the items in the checklist, except for No.8 since it was a one-off analysis initiative and did not involve deploying the solution in a production environment:<br><br>\n",
    "\n",
    "<b>1. Frame the problem and look at the big picture.</b><br>\n",
    "The objective of the project was to analyze the data for geospatial/temporal patterns and to predict the number of bicycle rides likely to occur on a given day.<br><br>\n",
    "<b>2. Get the data.</b><br>\n",
    "The data was downloaded from the City of Toronto open data website as Excel files.<br><br>\n",
    "<b>3. Explore the data to gain insights.</b><br>\n",
    "Exploratory data analysis was carried out. A few ambiguities were found regarding the timestamp values in the data. An email was sent out to the City of Toronto open data team to seek clarifications. When no reply was forthcoming, these were noted as assumptions and potential limitations to the validity of the analysis. <br><br>\n",
    "<b>4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms.</b><br>\n",
    "The data was cleaned to drop incomplete rows, categorial values were one-hot encoded, new additional calculated values added in order to prepare the data for mL algorithms. <br><br>\n",
    "<b>5. Explore many different models and short-list the best ones.</b><br>\n",
    "<b>6. Fine-tune your models and combine them into a great solution.</b><br>\n",
    "Only two models were applied and compared: Linear Regression and Random Forest Regression. The project could have done better on this item: a few more models could have been applied and a grid search performed to also include hyper-parameter tuning.<br><br> \n",
    "<b>7. Present your solution.</b><br>\n",
    "A graphical animated representation of the total rides on a given day was built and presented to the audience. This really helped identify intra-day patterns within the data. Wherever possible, generic terms were used instead of more arcane mathematical or statistical terms and graphical comparisons of both models used was presented along with the rationale behind final model selection.\n",
    "\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
